\chapter{Discussion}
\label{chap:discussion}

In this chapter, we will discuss the results of our experiments, and how they line up with our research questions posed in \cref{chap:introduction}. We will also outline any future work.
This chapter provides a discussion of what implications the results of the experiments has, and presents different aspects of the work conducted.


The first question regarding the state of the art in event correlation has been addressed in Chapter \cref{chap:background} where we have highlighted relevant studies and options for doing event correlation. We highlighted several different methods for doing event correlation.

% How can we improve the way real time event correlation is done for Windows Event Logs
We have considered multiple ways that we can improve 

We reimplemented what we considered the most important parts of \acrshort{SEC} in Go, taking advantage of Go being a compiled program. As seen in \n{REF}, this showed a great increase in the event throughput of the system. As discussed, we added concurrency and threading, which allowed us to utilize the full capacity of the processor. As seen in  \n{REF}, this lead to a even greater event throghput.

We also implemented a new way to pre-handle event logs when ingesting. We called this tokenizing,  \n{REF} and along with using Sigma \n{REF} as a new rule format, we were able to increase the throughput even further, as seen by  \n{REF}.

As outlined in experiments  \n{REF}, we identified two different ways to do context locking, and showed that for larger datasets, using the rule-based context mutex gave some increase in the event throughput  \n{REF}.

This shows that we were not only able to improve the way real time event correlation is done for Windows Event Logs, but also show that our improvements give significant performance benefits.

First of all we will extrapolate some numbers from the Mordor datasets. As discussed in \cref{sec:dataset-analysiss}, the second scenario had an average events per 10 seconds of 678. This gives us 67.8 events per second. If we consider that the dataset contained 8 users and 5 hosts, we can try to make some assumptions regarding real world environments. If we consider an environment with 100 hosts, that would give us a ballpark estimation of 1356 events per second. If we consider an environment with 500 hosts, that brings our estimation to 6780 events per second. This is not taking into account any peaks in the data. If we consider the highest peak in the first scenario, as seen in \cref{fig:10-sec-day-1}. Given a network size of 500 hosts, that would give us a peak at about 22 800 events per second. Now, that is probably unrealistic, as not all the hosts in the network would peak at the same time, producing massive amount of logs.

\iffalse
What if we use more rules?

\fi

\iffalse
Interpretations: what do the results mean?
Implications: why do the results matter?
Limitations: what canâ€™t the results tell us?
Recommendations: what practical actions or scientific studies should follow?
\fi


\section{Research questions}
...\\
The research presented in this thesis aims at improving real time event correlation...


The experiments conducted in this thesis evaluated a subset of possible features that might improve the performance of real time event correlation.
We chose to compare our solution against \acrshort{sec}, as that seems to be the most popular open-source software for rule-based event correlation and used in a wide variety of sectors. 

First of all we implemented a new solution that used the same rulesets at \acrshort{sec}, but implemented it using the compiled language Go. Running this using equal conditions like the same dataset, and only a single core, we were able to outperform SEC with 20-40\% using the high signal low noise dataset, and up to 89-135\% when comparing with the baseline dataset. This clearly shows the benefits of utilizing a compiled language when performance is an important criteria.

We implemented a better time management system that extracts the UTC timestamp from the log, and uses that for the time-based correlation as opposed to SEC which uses the time of when SEC reads the log line from input. The difference here does not play a role processing-wise, as the timestamps in the datasets are set to a single point in time, which replicates how SEC works in our new solution. In a real world scenario this would not be the case, and we consider our solution to be a better implementation than the one used in SEC.

We implemented functionality to take full advantage of the system hardware by using all cores available to use. This gave us an even bigger increase in throughput compared to both SEC and our own implementation using only a single core. We saw performance improvements of 59-80\% comparing our multi-threaded version to our single core version using the high signal low noise dataset, and improvements of 33-68\% when using the baseline dataset.

Lastly we implemented some changes to our solution that would depend less on regular expressions. To do this, we did two major changes: First we rewrote parts of the ingestion to tokenize each log entry, then we rewrote the rule parser to use Sigma rules instead. The benefits of this was clear, as we saw an even bigger performance boost..\n{Add some numbers here pls}

\begin{itemize}
    \item We were able to beat SEC in performance by implementing it using a compiled language and utilizing threading
    \item We were further able to enhance the speed by utilizing tokenization of the logs and using different rules
\end{itemize}

\section{Limitations of the study}
\label{sec:limitations}
We did not implement a one-to-one copy of \acrshort{sec} as we did not consider that to be of importance. We chose those features that we considered valuable. In addition, we did not create full feature parity with Sigma, only the parts necessary.

\section{Future work}
\label{sec:futurework}


\begin{itemize}
    \item Modularity
    \item Broader log support
    \item Distributed/scaling
\end{itemize}

We consider broader log support to be fairly simple to implement in the future. In addition, we focused on Sysmon as a subset of Windows Event logs, and expanding the ability to ingest regular Windows Event log is already done, but was not considered relevant as part of this thesis.

Distributed scaling: What could it tell us? Even more performance, harder to implement. Shared context is very tricky.

\todo{What could be expanded further upon in the future?}
\todo{Are there any experiments that we could have done, but didn't have the time to do? What could they tell us that we already didn't know?}
Full feature-parity with Sigma? With SEC?